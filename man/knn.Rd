% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knn.R
\name{knn}
\alias{knn}
\title{Weighted K-Nearest Neighbors}
\usage{
knn(
  formula,
  training_data,
  test_data,
  k = 1,
  weights = NULL,
  algorithm = c("kd_tree", "cover_tree", "brute")
)
}
\arguments{
\item{formula}{Formula like one would use for \code{lm()}}

\item{training_data}{The training data, in the form of a data frame}

\item{test_data}{The test data, in the form of a data frame}

\item{k}{The number of nearest neighbors}

\item{weights}{A vector of weights}

\item{algorithm}{Nearest neighbor search algorithm.}
}
\value{
An object with fields \code{predictions} and \code{probabilities}. \code{predictions} is a vector
of the same length as the number of test observations indicating the predicted classes, and
\code{probabilities} is a tibble with columns \code{observation}, \code{class}, and \code{probability}.
}
\description{
Carry out weighted KNN, e.g. to handle imbalanced classes.
}
\examples{
formula = y ~ x
training_data <- data.frame(x = 1:6, y = factor(c(1, 1, 1, 2, 2, 3)))
test_data <- data.frame(x = 1:6)
weights <- exp(1:6)
k <- 3
knn(formula = formula,
training_data = training_data,
test_data = test_data,
k = k,
weights = weights)
}
